Thursday, April 12, 2012: up to Flip in the in-class examples, except that we skipped single and double taps. Play with everything and do all the exercises. Write a project named Apr19 and upload it to a GitHub repository named Apr19. The project should detect gestures with a gesture recognizer, and do animation, sound, flipping, and/or other interesting stuff. A long time ago in a galaxy far, far away...

What this actually does:
 - Flip between two views. Flipping is triggered with double tap gesture.
 
 - The first view: 
	- Contains a bunch of UIImageViews. Each of these UIImageViews have a head image with a transparent background.
	- Touch on the view will move the head to the point Touch. A sound will play.
	- Each head has its own sound.
	- Animation of the movement of the head from where it was to where the user touched will be of the same duration as the sound being played.
	- Can shrink and expand all the heads by using pinch gesture. Will play sound.
	- Rotating the device will rotate the heads. Each head will rotate in its own delay and duration.
 
 - The second view:
	- Can draw lines.
	- First touch will indicate start point of the line. Second touch will indicate end point of the line.

Concepts explored:
	- Retrieve a file path from the resource bundle. [NSBundle mainBundle]
	- Retrieve an array of file paths from the resource bundle.
	- Using AVAudioPlayer to play mp3s.
	- Generating random numbers with arc4random().
	- Generating random CGFoat numbers with a custom function.
	- Animations on touch and gesture events with CGAffineTransform.

Concepts to explore:
	- Using appropriate sound player to play short sound files. AudioServicesPlaySystemSound
	- Simultaneously triggering gesture events by adopting the UIGestureRecognizerDelegate protocol.
	- Preserving previous transform on a View when applying a new one.
	- Using an Enum to interpret device orientation number.
	- Make UIImageView respond to events and gestures.
